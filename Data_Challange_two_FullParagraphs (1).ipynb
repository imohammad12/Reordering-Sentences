{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VRP-O_J0pblz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import transformers\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import heapq\n",
    "from scipy.stats import spearmanr\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lfo3ne-JnXmk"
   },
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p-K7qyyiljbm"
   },
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    \n",
    "  %cd $root\n",
    "  if os.path.isdir(path_data) == False:\n",
    "    os.makedirs(path_data)\n",
    "  %cd $path_data\n",
    "\n",
    "  # Download your kaggle coockies file and put it in root directory\n",
    "  !cp ../kaggle.json /root/.kaggle/\n",
    "  !kaggle competitions download -c stat946winter2021dc2\n",
    "  !unzip train.pkl.zip\n",
    "  !unzip test.pkl.zip\n",
    "\n",
    "def pkl_to_dict():\n",
    "\n",
    "  %cd $path_data\n",
    "  \n",
    "  FILE_NAME = 'train.pkl'\n",
    "  infile = open(FILE_NAME,'rb')\n",
    "  trainset = pickle.load(infile)\n",
    "\n",
    "\n",
    "  FILE_NAME = 'test.pkl'\n",
    "  infile = open(FILE_NAME,'rb')\n",
    "  testset = pickle.load(infile)\n",
    "\n",
    "  return trainset, testset\n",
    "\n",
    "def load_text(train_set, test_set):\n",
    "  \n",
    "  # Train sentences in the correct order\n",
    "  train_texts = []\n",
    "  test_texts = []\n",
    "  labels = []\n",
    "\n",
    "\n",
    "  # Concatenate the sentences in each paragraph\n",
    "  for parag in train_set:\n",
    "    # A single paragraph\n",
    "    p = \"\"\n",
    "    for i in range(len(parag['sentences'])):\n",
    "      if i != 0:\n",
    "        p += parag['sentences'][i] + ' [SEP] '\n",
    "      else:\n",
    "        p += ' [CLS] ' + parag['sentences'][i] + ' [SEP] '\n",
    "    \n",
    "    train_texts.append(p)\n",
    "    labels.append(parag[\"indexes\"])\n",
    "\n",
    "\n",
    "  for parag in test_set:\n",
    "    # A single paragraph\n",
    "    p = \"\"\n",
    "    for i in range(len(parag['sentences'])):\n",
    "      if i != 0:\n",
    "        p +=  parag['sentences'][i] + ' [SEP] '\n",
    "      else:\n",
    "        p += ' [CLS] ' + parag['sentences'][i] + ' [SEP] '\n",
    "    \n",
    "    test_texts.append(p)\n",
    "  \n",
    "  return train_texts, labels, test_texts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YsYNkGR7Wrvx"
   },
   "outputs": [],
   "source": [
    "root = %pwd # To Do replace the path with %pwd\n",
    "path_data = os.path.join(root, \"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8g_eIR2Omedt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/m25dehgh/testing_codes/stat/dc1/data\n"
     ]
    }
   ],
   "source": [
    "# # Download the datast To Do\n",
    "# # download_data()\n",
    "\n",
    "# Reading the data from pkl file\n",
    "train_set, test_set = pkl_to_dict()\n",
    "\n",
    "# Get list of paragraphs in form of a single string\n",
    "train_texts, labels, test_texts = load_text(train_set[:280000], test_set)\n",
    "\n",
    "# # redcuing the volume of data\n",
    "# train_texts = train_texts[:180000]\n",
    "# labels = labels[:180000]\n",
    "\n",
    "# # Seperating 10% of train data for validation\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, labels, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9mqOcP8mgi4"
   },
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3copNwDXYwgo"
   },
   "outputs": [],
   "source": [
    "def remove_big_parags(train_encodings):\n",
    "\n",
    "  # Removing paragraphs bigger than 512 token\n",
    "  i = 0\n",
    "  while i != len(train_encodings['attention_mask']):\n",
    "    \n",
    "    if train_encodings['attention_mask'][i][-1] == 1:\n",
    "      del train_encodings['input_ids'][i]\n",
    "      del train_encodings['attention_mask'][i]\n",
    "      i -= 1\n",
    "\n",
    "    i += 1\n",
    "\n",
    "  \n",
    "  return train_encodings\n",
    "\n",
    "\n",
    "def add_token_type_sep(encodings, desired_sep_nums=6):\n",
    "  '''\n",
    "    This function adds two new lists to the encoding ditionary: token_type_ids and sep_indxs # To Do\n",
    "    token_type_ids: list of size [encodings len, paragrraph len] \n",
    "    sep_indxs: list of size [encoding len, number of [SEP] tokens in the paragraph]. This list contian [SEP] indices.\n",
    "\n",
    "  '''\n",
    "  # The list of token types for all paragraphs\n",
    "  token_types = []\n",
    "  sep_indxs = []\n",
    "\n",
    "  for p_indx, parag in enumerate(encodings['input_ids']):\n",
    "    curr_type = 0\n",
    "    types_list = []\n",
    "    sep_toks = []\n",
    "\n",
    "    for i, tok in enumerate(parag):\n",
    "      types_list.append(curr_type)\n",
    "\n",
    "      if tok == 2:\n",
    "        sep_toks.append(i)\n",
    "        curr_type = 1 - curr_type # Flipping the token type\n",
    "\n",
    "    \n",
    "    if(len(sep_toks) < desired_sep_nums):\n",
    "      for i in range(desired_sep_nums - len(sep_toks)):\n",
    "        encodings['input_ids'][p_indx][-(i+1)] = 2\n",
    "        sep_toks.append(len(encodings['input_ids'][p_indx]) - (i+1))\n",
    "\n",
    "    sep_indxs.append(sep_toks)\n",
    "    token_types.append(types_list)\n",
    "    \n",
    "  \n",
    "  encodings['token_type_ids'] = token_types\n",
    "  encodings['sep_indxs'] = sep_indxs\n",
    "      \n",
    "  return encodings\n",
    "\n",
    "\n",
    "def save_obj(obj, path='train'):\n",
    "  \n",
    "  %cd $path_data\n",
    "\n",
    "  with open(path + \".txt\", \"wb\") as fp:\n",
    "    pickle.dump(obj, fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_saved_obj(path='train'):\n",
    "\n",
    "  %cd $path_data\n",
    "\n",
    "  with open(path + \".txt\", \"rb\") as fp:\n",
    "    obj = pickle.load(fp)\n",
    "\n",
    "\n",
    "  return obj\n",
    "\n",
    "def seq_to_out(seq):\n",
    "    out = []\n",
    "    if type(seq[0]) != list:\n",
    "        if type(seq) == str:\n",
    "            seq = [int(i) for i in seq]\n",
    "        for i in range(6):\n",
    "            out.append(seq.index(i))\n",
    "    else:\n",
    "        for each_seq in seq:\n",
    "            new_seq = []\n",
    "            for i in range(6):\n",
    "                new_seq.append(each_seq.index(i))\n",
    "            out.append(new_seq)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V7-p2ZqxkoCs"
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.DebertaTokenizer.from_pretrained('microsoft/deberta-base') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wd62yX1b6REo",
    "outputId": "bb203a85-425b-4736-8758-1274aa8643a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing big parags from train data\n",
      "adding token types and [SEP] postions list\n",
      "saving\n",
      "loading saved tokenized train encoding dictionary\n",
      "/home/m25dehgh/testing_codes/stat/dc1/data\n",
      "/home/m25dehgh/testing_codes/stat/dc1/data\n",
      "/home/m25dehgh/testing_codes/stat/dc1/data\n",
      "/home/m25dehgh/testing_codes/stat/dc1/data\n",
      "/home/m25dehgh/testing_codes/stat/dc1/data\n"
     ]
    }
   ],
   "source": [
    "# train_encodings = tokenizer(train_texts, add_special_tokens=False, truncation=True, padding=True, return_token_type_ids=False) \n",
    "# test_encodings = tokenizer(test_texts, add_special_tokens=False, truncation=True, padding=True, return_token_type_ids=False) \n",
    "# val_encodings = tokenizer(val_texts, add_special_tokens=False, truncation=True, padding=True, return_token_type_ids=False) \n",
    "\n",
    "\n",
    "# Removing paragraphs bigger than 512 token\n",
    "print(\"removing big parags from train data\")\n",
    "# train_encodings = remove_big_parags(train_encodings)\n",
    "\n",
    "\n",
    "# Adding the token_type_ids lists and list of [SEP] postions to to the encodings dictionaries\n",
    "print(\"adding token types and [SEP] postions list\")\n",
    "# train_encodings = add_token_type_sep(train_encodings)\n",
    "# test_encodings = add_token_type_sep(test_encodings)\n",
    "# val_encodings = add_token_type_sep(val_encodings)\n",
    "\n",
    "print(\"saving\")\n",
    "# save_obj(train_encodings, path='train_encodings_280k_FullPar')\n",
    "# save_obj(train_labels, path='train_labels_280k_FullPar')\n",
    "# save_obj(val_encodings, path='val_encodings_280k_FullPar')\n",
    "# save_obj(val_labels, path='val_labels_280k_FullPar')\n",
    "# save_obj(test_encodings, path='test_encodings_FullPar')\n",
    "\n",
    "print('loading saved tokenized train encoding dictionary')\n",
    "train_encodings = load_saved_obj(path='train_encodings_280k_FullPar')\n",
    "train_labels = load_saved_obj(path='train_labels_280k_FullPar')\n",
    "val_encodings = load_saved_obj(path='val_encodings_280k_FullPar')\n",
    "val_labels = load_saved_obj(path='val_labels_280k_FullPar')\n",
    "test_encodings = load_saved_obj(path='test_encodings_FullPar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cule-2adPr6m",
    "outputId": "61d0d102-e32b-460b-83e5-d542c4a8bde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 2, 5, 0, 1], [0, 1, 2, 5, 3, 4]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_to_out(val_labels[:2])\n",
    "# type(val_labels[:10][0]) == list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMzy76CDiZNI"
   },
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "opHkAQ5tgl82"
   },
   "outputs": [],
   "source": [
    "class NSPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels != None:\n",
    "          item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.labels)\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "RdWRnvCZikz5"
   },
   "outputs": [],
   "source": [
    "train_dataset = NSPDataset(train_encodings, seq_to_out(train_labels))\n",
    "val_dataset = NSPDataset(val_encodings, seq_to_out(val_labels))\n",
    "test_dataset = NSPDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tEvrUIqlAryX"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for i in val_encodings['sep_indxs'][1100]:\n",
    "#   print(val_encodings['input_ids'][1100][i])\n",
    "# train_encodings['sep_indxs'][1100]\n",
    "\n",
    "# test_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e1xfu88sBZS6"
   },
   "outputs": [],
   "source": [
    "# m = torch.nn.Softmax(dim=2)\n",
    "# ml = torch.nn.LogSoftmax(dim=2)\n",
    "# x = torch.rand(5,15,5)\n",
    "# print(torch.log(m(x))[2][10].sum())\n",
    "# ml(x)[2][10].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-L9ZM1YMji-z"
   },
   "source": [
    "# Creating Customized NSP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2UXXuS7uvpJb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = NSPDeBerta(sent_nums=3)\n",
    "# model.to(device)\n",
    "# model.train()\n",
    "\n",
    "# sent = ['[CLS] hello [SEP] akbar [SEP] how are [SEP] you.', '[CLS] This is  [SEP] a completely [SEP] She different beautiful [SEP]', ]\n",
    "# toks = tokenizer(sent, add_special_tokens=False, truncation=True, padding=True, return_token_type_ids=False)\n",
    "# toks = add_token_type_sep(toks)\n",
    "# toks = NSPDataset(toks)\n",
    "# tok_loader = DataLoader(toks, batch_size=2, shuffle=True)\n",
    "# for toks in tok_loader:\n",
    "#   input_ids = toks['input_ids'].to(device)\n",
    "#   attention_mask = toks['attention_mask'].to(device)\n",
    "#   # labels = toks['labels'].to(device)\n",
    "#   sep_pos=toks['sep_indxs']\n",
    "#   token_type_ids=toks['token_type_ids']\n",
    "#   input_ids\n",
    "#   outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, sep_pos=sep_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "inb6MMbOzcjQ"
   },
   "outputs": [],
   "source": [
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ciKvVx-ToYNT"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # toks['token_type_ids'] = torch.tensor(toks['token_type_ids'], dtype=torch.float)\n",
    "# # toks['sep_indxs'] = torch.tensor(toks['sep_indxs'])\n",
    "# print(toks)\n",
    "# # from transformers import DebertaTokenizer, DebertaModel\n",
    "# # import torch\n",
    "# # tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "# # model = DebertaModel.from_pretrained('microsoft/deberta-base')\n",
    "# # inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# outputs = model(toks['input_ids'], attention_mask=toks['attention_mask'], token_type_ids=toks['token_type_ids'], sep_pos=toks['sep_indxs'])\n",
    "# last_hidden_states = outputs.last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BYw1isjXEFr-"
   },
   "outputs": [],
   "source": [
    "# print(last_hidden_states.shape)\n",
    "# sep_pos = [i + j * 17 for j , i in enumerate(toks['sep_indxs'].numpy())]\n",
    "# sep_pos = torch.tensor(sep_pos)\n",
    "# last_hidden_states.view(-1,768)[sep_pos.view(-1)].view(2,-1 ,768).shape\n",
    "# sep_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8c7BDiDZ62HM"
   },
   "outputs": [],
   "source": [
    "brgik = False\n",
    "for i in range(len(test_dataset)):\n",
    "  for key, val in test_dataset[i].items():\n",
    "    if key == 'sep_indxs' and val[-1] == 510:\n",
    "      print('akbaaar error at', i)\n",
    "      print(val)\n",
    "      print(test_dataset[i]['input_ids'])\n",
    "      # brgik = True\n",
    "      # break\n",
    "  if brgik:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5n50lXCqRWq",
    "outputId": "b32ddddc-6015-4cae-cb7a-990001f45679"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = transformers.DebertaConfig.from_pretrained('microsoft/deberta-base')\n",
    "conf.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Yqhu8afLj2S0"
   },
   "outputs": [],
   "source": [
    "\n",
    "class NSPDeBerta(torch.nn.Module):\n",
    "  def __init__(self, sent_nums):\n",
    "    \"\"\"\n",
    "    To Do\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    super(NSPDeBerta, self).__init__()\n",
    "    self.sent_nums = sent_nums\n",
    "    self.DeBerta = transformers.DebertaModel.from_pretrained('microsoft/deberta-base')\n",
    "    self.conf = transformers.DebertaConfig.from_pretrained('microsoft/deberta-base')\n",
    "    self.linear1 = torch.nn.Linear(self.conf.hidden_size, self.conf.hidden_size)\n",
    "    self.linear2 = torch.nn.Linear(self.conf.hidden_size, self.sent_nums)\n",
    "    self.tan = torch.nn.Tanh()\n",
    "    self.log_soft = torch.nn.LogSoftmax(dim=2)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, token_type_ids, sep_pos):\n",
    "    \"\"\"\n",
    "    To Do\n",
    "    \n",
    "    \"\"\"\n",
    "    last_hidden_state = self.DeBerta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).last_hidden_state\n",
    "    \n",
    "    seq_len = input_ids.shape[1]\n",
    "    batch_size = input_ids.shape[0]\n",
    "\n",
    "    # Updating indices of [SEP] in a flatten 2-D matrixx of size (batch_size * seq_len) x (conf.hidden_size)\n",
    "    sep_batch_flatten_pos = [indx + j * seq_len for j , indx in enumerate(sep_pos.cpu().numpy())]\n",
    "    sep_batch_flatten_pos = torch.tensor(sep_batch_flatten_pos).to(device)\n",
    "\n",
    "    # The number of [SEP] positions is qeual to the number of sentences (self.sent_nums)\n",
    "    # Converting last hidden state of size (batch_size x seq_len x self.conf.hidden_size) to the last hidden states of [SEP] tokens (batch_size, number of sep tokens in each batch , self.conf.hidden_size)\n",
    "    sep_last_hidden_states = last_hidden_state.view(-1,self.conf.hidden_size)[sep_pos.view(-1)].view(batch_size, self.sent_nums , self.conf.hidden_size).to(device)\n",
    "\n",
    "    x = self.linear1(sep_last_hidden_states)\n",
    "    x = self.tan(x)\n",
    "    x = self.linear2(x)\n",
    "    \n",
    "    # Returning the probabilty of each of paraphraph positions for each sentence in each paraphraph\n",
    "    return self.log_soft(x)\n",
    "\n",
    "  \n",
    "  def save_model(self, loss, path='NSPDeberta',):\n",
    "  \n",
    "    %cd $root\n",
    "\n",
    "    model_path = os.path.join(root, 'BestModel/')\n",
    "    if os.path.isdir(model_path) == False:\n",
    "      os.makedirs(model_path)\n",
    "    \n",
    "    %cd %model_path\n",
    "\n",
    "    torch.save(self.state_dict(), path + 'loss_' + str(loss))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UofOwRMKt4Td"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "FcnUg0N_JxA0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 3 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_sents = 6\n",
    "batch_size = 8\n",
    "\n",
    "model = NSPDeBerta(num_sents)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f38decf6686448edad521cd97024eeb8",
      "0461f6e014a94dfdbce75be9397d0dc1",
      "58657624cecd4219b29d7b409aa1241e",
      "f305aa2df52e49fe854cbc8498646964",
      "d620206d74a54ac3ab8335a44ff3a252",
      "32198fb2c41c456dbf63af67986e5a7c",
      "5ac20fa30d224bb9ab94ef0deaa1539d",
      "bb3ad513dc5f43cab73b123ecf0f5eaf"
     ]
    },
    "id": "43SE5VYNjYDu",
    "outputId": "3adac352-f700-4198-c062-76c5699cf089",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "epoch :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-2a88c05a87d1>:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm(total=int(len(train_dataset) / batch_size)) as pbar:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3a674acc4b42bfa4bd1a1fc8046aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=31500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 - loss: 1.7957950830459595\n",
      "iteration: 100 - loss: 1.8009820902347564\n",
      "iteration: 200 - loss: 1.794909782409668\n",
      "iteration: 300 - loss: 1.7896342253684998\n",
      "iteration: 400 - loss: 1.7842701363563538\n",
      "iteration: 500 - loss: 1.78001478433609\n",
      "iteration: 600 - loss: 1.7701278674602507\n",
      "iteration: 700 - loss: 1.761880693435669\n",
      "iteration: 800 - loss: 1.7446945595741272\n",
      "iteration: 900 - loss: 1.7339966630935668\n",
      "iteration: 1000 - loss: 1.7238178956508636\n",
      "iteration: 1100 - loss: 1.7226910209655761\n",
      "iteration: 1200 - loss: 1.7137366402149201\n",
      "iteration: 1300 - loss: 1.7081771719455718\n",
      "iteration: 1400 - loss: 1.7140716207027435\n",
      "iteration: 1500 - loss: 1.7047246038913726\n",
      "iteration: 1600 - loss: 1.6941191959381103\n",
      "iteration: 1700 - loss: 1.7018040549755096\n",
      "iteration: 1800 - loss: 1.6984289193153381\n",
      "iteration: 1900 - loss: 1.6871208047866821\n",
      "iteration: 2000 - loss: 1.686605749130249\n",
      "iteration: 2100 - loss: 1.692801467180252\n",
      "iteration: 2200 - loss: 1.694716637134552\n",
      "iteration: 2300 - loss: 1.6793250691890718\n",
      "iteration: 2400 - loss: 1.6891641330718994\n",
      "iteration: 2500 - loss: 1.682789204120636\n",
      "iteration: 2600 - loss: 1.6907446050643922\n",
      "iteration: 2700 - loss: 1.6792287313938141\n",
      "iteration: 2800 - loss: 1.6789782273769378\n",
      "iteration: 2900 - loss: 1.6733839440345764\n",
      "iteration: 3000 - loss: 1.6844135546684265\n",
      "iteration: 3100 - loss: 1.6759449052810669\n",
      "iteration: 3200 - loss: 1.6630571365356446\n",
      "iteration: 3300 - loss: 1.6703747141361236\n",
      "iteration: 3400 - loss: 1.673178472518921\n",
      "iteration: 3500 - loss: 1.6681300377845765\n",
      "iteration: 3600 - loss: 1.6696280550956726\n",
      "iteration: 3700 - loss: 1.6786660754680633\n",
      "iteration: 3800 - loss: 1.6771375823020935\n",
      "iteration: 3900 - loss: 1.6772121858596802\n",
      "iteration: 4000 - loss: 1.6754936099052429\n",
      "iteration: 4100 - loss: 1.6685929536819457\n",
      "iteration: 4200 - loss: 1.6665751230716705\n",
      "iteration: 4300 - loss: 1.6708824110031129\n",
      "iteration: 4400 - loss: 1.6634842932224274\n",
      "iteration: 4500 - loss: 1.6674329936504364\n",
      "iteration: 4600 - loss: 1.6713596451282502\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-2a88c05a87d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simpenv38/lib/python3.8/site-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "criteria = torch.nn.NLLLoss()\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"=================================\")\n",
    "    print(\"epoch : \", epoch)\n",
    "\n",
    "    with tqdm(total=int(len(train_dataset) / batch_size)) as pbar:\n",
    "\n",
    "        for iteration, batch in enumerate(train_loader):\n",
    "            pbar.update(1)\n",
    "            optim.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            sep_pos=batch['sep_indxs'].to(device)\n",
    "            token_type_ids=batch['token_type_ids'].to(device)\n",
    "            output = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, sep_pos=sep_pos)\n",
    "            loss = torch.tensor([0], requires_grad=True, dtype=torch.float).to(device)\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                loss += criteria(output[b], labels[b])\n",
    "            loss /= batch_size\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            if iteration % 100 == 0:\n",
    "                mean = np.array(losses).mean()\n",
    "                print(\"iteration: {} - loss: {}\".format(iteration, mean))\n",
    "                losses.clear() \n",
    "\n",
    "# model.save_model(losses[-1], 'NSPDeberta_batch' + str(batch_size) + '_')\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSrDukPKscbV",
    "outputId": "159b0880-8bdb-4d2b-aedd-3edc3e84248e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555086336"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bat = next(iter(train_loader))\n",
    "input_ids = bat['input_ids'].to(device)\n",
    "torch.cuda.memory_allocated(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YQCmOjZQt06O"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYhv4r_btFCS",
    "outputId": "1ee44b3a-0120-4c44-d072-f5edf3609e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14593946112"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0) \n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GActGfvs__BV",
    "outputId": "11e0d315-969b-4930-85f3-46c88391bd2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in range(len(train_encodings['attention_mask'])):\n",
    "  s += train_encodings['attention_mask'][i][-1] == 1\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OMy-6D5G_kG"
   },
   "outputs": [],
   "source": [
    "for iteration, batch in enumerate(train_loader):\n",
    "  print(iteration)\n",
    "  print(len(batch))\n",
    "  print(batch['labels'].shape)\n",
    "  print(batch['input_ids'].shape)\n",
    "  # len(bat[10]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roXnk3aP-Mhs",
    "outputId": "7663b9db-5407-4990-d1ec-a62534991f37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = tokenizer(train_texts[0:1000], truncation=True, padding=True)\n",
    "# print(train_texts[0])\n",
    "# test_text[0]\n",
    "# train_tex\n",
    "\n",
    "s = 0\n",
    "for i in range(1000):\n",
    "  s += a['attention_mask'][i][-1] == 0\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddZoDG0mKMRZ",
    "outputId": "881cdafe-7670-48f9-ccc5-ba19661122db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531203"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encodings['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QAtRFDowSTK",
    "outputId": "69c637e8-7d1e-45f4-d225-46f805d76af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          13021         513       10621           0        1886       12232\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDzKgQJVk8c3",
    "outputId": "50626910-eb10-401c-e3a5-28841aed4e17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[[1, 42891, 2, 677, 4901, 449, 4134, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 42891, 2, 100, 236, 7, 213, 184, 213, 213, 213, 2, 2515, 16, 23523, 2721, 2]] \n",
      " [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] \n",
      " [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "sent = ['[CLS] hello [SEP] akbar khan', '[CLS] hello [SEP] I want to go home go go go [SEP] She is fucking beautiful [SEP]', ]\n",
    "toks = tokenizer(sent, add_special_tokens=False, truncation=True, padding=True, return_token_type_ids=False)\n",
    "tok_type = tokenizer.create_token_type_ids_from_sequences(toks['input_ids'][0], toks['input_ids'][1])\n",
    "print(tok_type)\n",
    "# tokenizer.convert_ids_to_tokens(toks)\n",
    "# print(toks['input_ids'],'\\n', toks['attention_mask'], '\\n',toks['token_type_ids'])\n",
    "toks = add_token_type_sep(toks)\n",
    "print(toks['input_ids'],'\\n', toks['attention_mask'], '\\n',toks['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGT8huBumhC6"
   },
   "outputs": [],
   "source": [
    "# !rm -rf test.pkl.zip\n",
    "# !rm -rf train.pkl.zip\n",
    "# !rm -rf sample_submission.csv\n",
    "# download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lvjBMhZKbOEP"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8e98108afb09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_set' is not defined"
     ]
    }
   ],
   "source": [
    "len(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9Yikjb9flNZ",
    "outputId": "4d9adea7-ca94-4171-8b28-3b451c932d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He served in the Oregon House of Representatives from 2009 to 2014, representing inner Southeast and Northeast Portland, and on the County Commission for Multnomah County, Oregon from June 2014 to December 2016.', 'In 2016, Bailey ran for mayor of Portland, losing to Ted Wheeler.', 'Jules Bailey (born November, 1979) is a former Multnomah County Commissioner who now works at the Oregon Beverage Recycling Cooperative.', 'Early life and education \\nBailey was raised in Portland, Oregon and graduated from Lincoln High School.', \"He earned a bachelor's degree in  Lewis & Clark College and received MPA/URP from Princeton University\\n\\nBailey studied in a dual-degree graduate program at Princeton University's Woodrow Wilson School of Public and International Affairs.\", 'In January 2017, he began working for the Oregon Beverage Recycling Cooperative as the chief stewardship officer.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ID': 11,\n",
       " 'indexes': [1, 3, 0, 2, 4, 5],\n",
       " 'sentences': ['The ship was sunk in 1940.',\n",
       "  'The ships displaced  at (standard) load and  at deep load.',\n",
       "  \"Orage was a  (torpilleur d'escadre) built for the French Navy during the 1920s.\",\n",
       "  'Design and description\\nThe Bourrasque class had an overall length of , a beam of , and a draft of .',\n",
       "  'They were powered by two geared steam turbines, each driving one propeller shaft, using steam provided by three du Temple boilers.',\n",
       "  'The turbines were designed to produce , which would propel the ship at .']}"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_texts[0])\n",
    "train_set[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ad1RfMSToJF1"
   },
   "outputs": [],
   "source": [
    "avg_len = 0\n",
    "for i, parag in enumerate(train_set):\n",
    "  parag_len = 0\n",
    "  for sent in parag[\"sentences\"]:\n",
    "    parag_len +=len(sent)\n",
    "  if (i % 10000 == 0):\n",
    "    print(parag_len)\n",
    "\n",
    "  avg_len += float(parag_len) * 1/(len(train_set))\n",
    "print(avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R531P_04ojf_",
    "outputId": "20b7709b-d2e4-41a8-9716-310f99ded9ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521463"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigger_than_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rtHVKESzq0wI",
    "outputId": "4029b7b0-fe8d-491d-d962-6ff260fbe71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) (1, 1)\n",
      "(0, 0) (1, 2)\n",
      "(0, 0) (1, 3)\n",
      "(0, 0) (1, 4)\n",
      "(0, 0) (1, 5)\n",
      "(0, 1) (2, 2)\n",
      "(0, 1) (2, 3)\n",
      "(0, 1) (2, 4)\n",
      "(0, 1) (2, 5)\n",
      "(0, 2) (3, 3)\n",
      "(0, 2) (3, 4)\n",
      "(0, 2) (3, 5)\n",
      "(0, 3) (4, 4)\n",
      "(0, 3) (4, 5)\n",
      "(0, 4) (5, 5)\n",
      "(1, 1) (2, 2)\n",
      "(1, 1) (2, 3)\n",
      "(1, 1) (2, 4)\n",
      "(1, 1) (2, 5)\n",
      "(1, 2) (3, 3)\n",
      "(1, 2) (3, 4)\n",
      "(1, 2) (3, 5)\n",
      "(1, 3) (4, 4)\n",
      "(1, 3) (4, 5)\n",
      "(1, 4) (5, 5)\n",
      "(2, 2) (3, 3)\n",
      "(2, 2) (3, 4)\n",
      "(2, 2) (3, 5)\n",
      "(2, 3) (4, 4)\n",
      "(2, 3) (4, 5)\n",
      "(2, 4) (5, 5)\n",
      "(3, 3) (4, 4)\n",
      "(3, 3) (4, 5)\n",
      "(3, 4) (5, 5)\n",
      "(4, 4) (5, 5)\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "nums = 0\n",
    "for l in range(5):\n",
    "  for k in range(l, 5):\n",
    "    for r in range(k + 1, 6):\n",
    "      print((l, k), (k+1, r))\n",
    "      nums += 1\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEVAlZgBj7R0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data-Challange-two-FullParagraphs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "simpenv38",
   "language": "python",
   "name": "simpenv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0461f6e014a94dfdbce75be9397d0dc1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32198fb2c41c456dbf63af67986e5a7c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58657624cecd4219b29d7b409aa1241e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  9%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32198fb2c41c456dbf63af67986e5a7c",
      "max": 40500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d620206d74a54ac3ab8335a44ff3a252",
      "value": 3622
     }
    },
    "5ac20fa30d224bb9ab94ef0deaa1539d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb3ad513dc5f43cab73b123ecf0f5eaf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d620206d74a54ac3ab8335a44ff3a252": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f305aa2df52e49fe854cbc8498646964": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb3ad513dc5f43cab73b123ecf0f5eaf",
      "placeholder": "​",
      "style": "IPY_MODEL_5ac20fa30d224bb9ab94ef0deaa1539d",
      "value": " 3622/40500 [47:37&lt;8:04:57,  1.27it/s]"
     }
    },
    "f38decf6686448edad521cd97024eeb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58657624cecd4219b29d7b409aa1241e",
       "IPY_MODEL_f305aa2df52e49fe854cbc8498646964"
      ],
      "layout": "IPY_MODEL_0461f6e014a94dfdbce75be9397d0dc1"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
